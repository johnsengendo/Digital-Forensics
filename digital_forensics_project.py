# -*- coding: utf-8 -*-
"""Digital forensics Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B3nFIPcY-l-z9nPMVb0J-Y_v8MkXFJqU

# This project trains a generator on how to get better by generating fake images that are continuously rejected by the discriminator.

##Setting up connection to my drive where the dataset is stored.
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install imageio
!pip install git+https://github.com/tensorflow/docs

"""##Importing useful libraries."""

# Commented out IPython magic to ensure Python compatibility.
import glob
import tensorflow as tf
import pandas as pd
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from tensorflow.keras import layers
import time
import csv
# %matplotlib inline
from keras.utils.vis_utils import plot_model
from IPython import display
from keras import preprocessing
from keras.models import Sequential
from keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape

"""##Downloading the fashion dataset from the drive.

"""

train_data = pd.read_csv('/content/drive/My Drive/project/DF/fashion-mnist_train.csv')

"""##Cleaning the data by droping off the labels from the dataset.

"""

X_train = train_data.drop('label',axis=1)
X_train.head()

X_train=X_train.values
print(X_train.shape)

"""## I normalise the dataset and convert it to type float.

"""

X_train=X_train.reshape(-1,28,28,1).astype('float32')
X_train = (X_train - 127.5)/127.5
print(X_train.shape)

"""## Setting the batch_size.

"""

BUFFER_SIZE = 60000
BATCH_SIZE = 256

train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

"""## Creating the models.

### The Generator

Takes in an input which is 100 random digits long and outputs a 28 by 28 image. I first make a dense layer at the begining, I make it 7 by 7 and 256 filters. I use  batchnormalization sothat the output doen't explode. In the second step I use Conv2DTranspose (upsampling) with fiters set to 128.
"""

def make_generator_model():
    model = tf.keras.Sequential(name='generator')
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 1)

    return model

generator = make_generator_model()
generator.build()
generator.summary()

"""## Using the noise to generate images from the generator."""

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

"""# The Discriminator.

"""

def make_discriminator_model():
    model = tf.keras.Sequential(name='discriminator')
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

discriminator = make_discriminator_model()
discriminator.summary()

"""## Defining the loss and optimizers for both models.

"""

# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

"""
## Discriminator loss.





"""

def discriminator_loss(real_output, fake_output):
    
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    
    return total_loss

"""##Generator loss.


"""

def generator_loss(fake_output):
    
    gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)
    
    return gen_loss

"""The discriminator and the generator optimizers are different since I train two networks separately."""

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

"""## Saving checkpoints which can be helpful in case a long running training task is interrupted."""

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

"""## Defining the training loop.

"""

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16
seed = tf.random.normal([num_examples_to_generate, noise_dim])

"""
## The training loop begins with the generator receiving a random seed as input. """

# Notice the use of `tf.function`
# This annotation causes the function to be "compiled".
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:

      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)


    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    # Produce images
    display.clear_output(wait=True)
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epochs,
                           seed)

def generate_and_save_images(model, epoch, test_input):
  # Notice `training` is set to False.
  # This is so all layers run in inference mode (batchnorm).
  predictions = model(test_input, training=False)

  fig = plt.figure(figsize=(4, 4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
      plt.axis('off')

  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
  plt.show()

"""## I train the model by calling the `train()` function defined above to train the generator and discriminator simultaneously  for a defined epochs. *Note*, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).

 
"""

train(train_dataset, EPOCHS)

"""## Restoring the latest checkpoint."""

checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
